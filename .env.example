# =============================================================================
# TabGraphSyn Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit the .env file to version control!
# To generate a secure SECRET_KEY, run: python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"
# =============================================================================

# Django Core Settings
# -----------------------------------------------------------------------------
DJANGO_SETTINGS_MODULE=tabgraphsyn_site.settings

# SECRET_KEY: Used for cryptographic signing. MUST be unique and secret in production!
# Generate a new one using: python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"
SECRET_KEY=your-secret-key-here-CHANGE-THIS-IN-PRODUCTION

# DEBUG: Set to False in production! Exposes sensitive information when True.
DEBUG=True

# ALLOWED_HOSTS: Comma-separated list of domains allowed to serve the app
# Example: ALLOWED_HOSTS=yourdomain.com,www.yourdomain.com,127.0.0.1
ALLOWED_HOSTS=127.0.0.1,localhost

# MongoDB Configuration
# -----------------------------------------------------------------------------
# Connection string for MongoDB (stores user sessions and run history)
# Local: mongodb://localhost:27017
# With auth: mongodb://username:password@host:port
# Docker: mongodb://mongodb:27017
TABGRAPHSYN_MONGO_URI=mongodb://localhost:27017
TABGRAPHSYN_MONGO_DB=tabgraphsyn
TABGRAPHSYN_MONGO_USERS_COLLECTION=users
TABGRAPHSYN_MONGO_RUNS_COLLECTION=runs

# Pipeline Configuration
# -----------------------------------------------------------------------------
# Path to the Python executable for running the ML pipeline
# This should point to your conda/virtual environment with ML dependencies
# Windows example: C:\ProgramData\miniconda3\envs\tabgraphsyn\python.exe
# Linux example: /home/user/miniconda3/envs/tabgraphsyn/bin/python
TABGRAPHSYN_PIPELINE_PYTHON=C:\ProgramData\miniconda3\envs\tabgraphsyn\python.exe

# Database (Optional - if using PostgreSQL instead of SQLite)
# -----------------------------------------------------------------------------
# Uncomment these if you want to use PostgreSQL for Django's database
# DATABASE_ENGINE=django.db.backends.postgresql
# DATABASE_NAME=tabgraphsyn
# DATABASE_USER=postgres
# DATABASE_PASSWORD=postgres
# DATABASE_HOST=db
# DATABASE_PORT=5432

# Celery Configuration (Task Queue for Background Jobs)
# -----------------------------------------------------------------------------
# Redis is used as the message broker and result backend for Celery
# Local development: redis://localhost:6379/0
# Docker: redis://redis:6379/0
# Production with auth: redis://:password@host:port/db
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Celery Task Settings
# Task timeout in seconds (ML pipeline can take a long time - set to 2 hours)
CELERY_TASK_TIME_LIMIT=7200
# Soft time limit (task will receive exception but can clean up)
CELERY_TASK_SOFT_TIME_LIMIT=7000
